# fine_tune_data_load.py

from datasets import load_dataset
import json

# 1Ô∏è‚É£ Load the dataset (train split)
print("üöÄ Loading dataset from Hugging Face...")
dataset = load_dataset("agentsea/wave-ui-25k", split="train")

# 2Ô∏è‚É£ Total samples
print("Total samples:", len(dataset))

# 3Ô∏è‚É£ Function to create 'output' field
def create_output(sample):
    instruction = sample.get("instruction", "")
    description = sample.get("description", "")
    purpose = sample.get("purpose", "")
    expectation = sample.get("expectation", "")

    # Combine into one string for fine-tuning
    output_text = f"Instruction: {instruction}\nDescription: {description}\nPurpose: {purpose}\nExpectation: {expectation}"
    return output_text

# 4Ô∏è‚É£ Preview first few samples
print("\nüìÑ Preview of first 3 samples:")
for i in range(3):
    sample = dataset[i]
    output_text = create_output(sample)
    
    print(f"\nSample {i}:")
    print("Instruction:", sample["instruction"])
    print("Output:", output_text)

# 5Ô∏è‚É£ Process entire dataset for fine-tuning
print("\n‚ö° Processing entire dataset and saving to JSONL...")
processed_samples = []

for sample in dataset:
    processed_samples.append({
        "instruction": sample["instruction"],
        "output": create_output(sample)
    })

# Save to JSONL file
jsonl_file = "waveui_finetune.jsonl"
with open(jsonl_file, "w", encoding="utf-8") as f:
    for item in processed_samples:
        f.write(json.dumps(item) + "\n")

print(f"‚úÖ Dataset saved as {jsonl_file}")
